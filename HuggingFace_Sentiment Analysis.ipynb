{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58824539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp37-cp37m-win_amd64.whl (444.0 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=e372818b90d4c4a7ae535e6f902ff6dca00b4b9c9591b11e585e6729b6d2a159\n",
      "  Stored in directory: c:\\users\\annar\\appdata\\local\\pip\\cache\\wheels\\3f\\e3\\ec\\8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built termcolor\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.6 opt-einsum-3.3.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "#for sentiment analysis we can use PyTorch or Tensor flow, in this case I've already intalled pytorch so just in case i'm installing tensorflow\n",
    "#we're using PyTorch for this exercise\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b6a8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (4.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: requests in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from transformers) (3.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\annar\\anaconda3\\envs\\mlenv\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed35f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12fbfecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839b212",
   "metadata": {},
   "source": [
    "# EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51713d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67368991ab540eda41b0147914f51d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9dcb371a8744e3bd9336e337afadd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8dd18b91be4fc99f68c092dbeb3cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90c3b235ea947afab22285f19530550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#specify the task that we want, we can find the list in https://huggingface.co/models\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835844e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9989567995071411}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example shows that we're 99% the text is NEGATIVE sentiment\n",
    "example_results = classifier(\"I really miss my country, I wish I can go more often\")\n",
    "example_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "175c74ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'NEGATIVE', 'score': 0.9989567995071411}\n",
      "{'label': 'POSITIVE', 'score': 0.9998181462287903}\n",
      "{'label': 'NEGATIVE', 'score': 0.9992493987083435}\n",
      "{'label': 'POSITIVE', 'score': 0.6489291191101074}\n",
      "{'label': 'NEGATIVE', 'score': 0.9972866773605347}\n"
     ]
    }
   ],
   "source": [
    "#we can also give this pipeline a list of texts to analyse \n",
    "example_results_2 = classifier([\"I really miss my country, I wish I can go more often\", \n",
    "                                \"I love sushi\", \n",
    "                                \"this is disscusting, I feel like the news are only giving more stress to people.\", \n",
    "                               \":)\",\n",
    "                               \"I dont know yet, but I'm looking for the answer.\"])\n",
    "\n",
    "\n",
    "for results in example_results_2:\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267c221",
   "metadata": {},
   "source": [
    "# EXAMPLE WITH TOKENIZDER AND A MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0260121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to tonkenize our data, the autotokenizer is a generic class and the next one is more specific\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c12b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can get another model here:\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74e22fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from_pretrained is a popular function in hugging face \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62c0ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we add the model and the tokenizer\n",
    "classifier_2 = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3debb206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'NEGATIVE', 'score': 0.9989567995071411}\n",
      "{'label': 'POSITIVE', 'score': 0.9998181462287903}\n",
      "{'label': 'NEGATIVE', 'score': 0.9992493987083435}\n",
      "{'label': 'POSITIVE', 'score': 0.6489291191101074}\n",
      "{'label': 'NEGATIVE', 'score': 0.9972866773605347}\n"
     ]
    }
   ],
   "source": [
    "#the results are the same because we're using the classifier\n",
    "example_results_3 = classifier([\"I really miss my country, I wish I can go more often\", \n",
    "                                \"I love sushi\", \n",
    "                                \"this is disscusting, I feel like the news are only giving more stress to people.\", \n",
    "                               \":)\",\n",
    "                               \"I dont know yet, but I'm looking for the answer.\"])\n",
    "\n",
    "\n",
    "for results in example_results_3:\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82b4f300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['i', 'really', 'miss', 'my', 'country', ',', 'i', 'wish', 'i', 'can', 'go', 'more', 'often']\n"
     ]
    }
   ],
   "source": [
    "#let's try now to use tokenize the sentence, if we only print the tokenizer.tokenize we got the 13 words separated\n",
    "tokens = tokenizer.tokenize(\"I really miss my country, I wish I can go more often\")\n",
    "\n",
    "print(f'Tokens: {tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f670ea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens IDs:[1045, 2428, 3335, 2026, 2406, 1010, 1045, 4299, 1045, 2064, 2175, 2062, 2411]\n"
     ]
    }
   ],
   "source": [
    "#The token IDs are the mathematical word representation\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f'Tokens IDs:{token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef89d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs:{'input_ids': [101, 1045, 2428, 3335, 2026, 2406, 1010, 1045, 4299, 1045, 2064, 2175, 2062, 2411, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "#we also can apply tokenizer directly and we get another result\n",
    "#in the IDs the 101 means the beginning and the 102 the end of the sentence\n",
    "#we can use this input token IDs to put them directly in our model\n",
    "\n",
    "input_ids = tokenizer(\"I really miss my country, I wish I can go more often\")\n",
    "\n",
    "print(f'Input IDs:{input_ids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392e6f0",
   "metadata": {},
   "source": [
    "# MULTIPLE FRASES TOKENIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "707539ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2428,  3335,  2026,  2406,  1010,  1045,  4299,  1045,\n",
       "          2064,  2175,  2062,  2411,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  1045,  2293, 10514,  6182,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2023,  2003,  4487,  4757,  7874,  3436,  1010,  1045,  2514,\n",
       "          2066,  1996,  2739,  2024,  2069,  3228,  2062,  6911,  2000,  2111,\n",
       "          1012,   102],\n",
       "        [  101,  1024,  1007,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  1045,  2123,  2102,  2113,  2664,  1010,  2021,  1045,  1005,\n",
       "          1049,  2559,  2005,  1996,  3437,  1012,   102,     0,     0,     0,\n",
       "             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is how we get the input ids for several frases, they are inside a dictionary, separated by 101 and 102\n",
    "\n",
    "X_train = [\"I really miss my country, I wish I can go more often\", \n",
    "          \"I love sushi\", \n",
    "          \"this is disscusting, I feel like the news are only giving more stress to people.\", \n",
    "          \":)\", \n",
    "          \"I dont know yet, but I'm looking for the answer.\"]    \n",
    "\n",
    "#return_tensors=\"pt\" is for pytorch if we want to use tensorflow you need to make other steps \n",
    "#for more directions watch youtube.com/watch?v=GSt00_-0ncQ&t=1s minute 30:56\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d196294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[ 3.7767, -3.0878],\n",
      "        [-4.1509,  4.4612],\n",
      "        [ 3.9423, -3.2516],\n",
      "        [-0.2246,  0.3897],\n",
      "        [ 3.2588, -2.6480]]), hidden_states=None, attentions=None)\n",
      "tensor([[9.9896e-01, 1.0432e-03],\n",
      "        [1.8186e-04, 9.9982e-01],\n",
      "        [9.9925e-01, 7.5056e-04],\n",
      "        [3.5107e-01, 6.4893e-01],\n",
      "        [9.9729e-01, 2.7134e-03]])\n",
      "tensor([0, 1, 0, 1, 0])\n",
      "['NEGATIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "#we are going to pass the batch to our model, the ** means to unpack the dictionary\n",
    "#inside tensor([[are the probabilities]])\n",
    "# if our result has a loss, we can put labels=torch.tensor([1,0]) next to the **batch\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    print(outputs)\n",
    "    \n",
    "    #inside tensor([[are the probabilities]])\n",
    "    predictions = F.softmax(outputs.logits, dim=1)\n",
    "    print(predictions)\n",
    "    \n",
    "    #give us the max and min\n",
    "    labels = torch.argmax((predictions), dim=1)\n",
    "    print(labels)\n",
    "    \n",
    "    #id2label give us the class name POSITIVE NEGATIVE\n",
    "    labels = [model.config.id2label[label_id] for label_id in labels.tolist()]\n",
    "    print(labels)\n",
    "\n",
    "#NOTEEE!!! THE classifier pipeline GAVE US THE SAME RESULT AND MORE CLEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d3831d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we're naming the folder \"saved\"\n",
    "saved_directory = \"saved\"\n",
    "\n",
    "#its going to save the jsons with the information above\n",
    "tokenizer.save_pretrained(saved_directory)\n",
    "model.save_pretrained(saved_directory)\n",
    "\n",
    "#load to directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_directory)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(saved_directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509196f",
   "metadata": {},
   "source": [
    "# CHANGE MODEL TO SPANISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d74a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to https://huggingface.co/models and select text classifaction, there you can select your language and copy it \n",
    "model_name_2 = \"JonatanGk/roberta-base-bne-finetuned-cyberbullying-spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5ddd0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3b3a9fe57c4c4699e9d34dfa426089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46dc8549d6f4c8a921e833023e32b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/831k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a635eca5d494253b30bf219ad648654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/497k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28912a3a4fc241de877805a617909a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8ccd0497204a70aeff3ffb334cb63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f265e60b28f3475cb1e80deb9d4aa9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/911 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0902d53249064467a40efab868ba304b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/476M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  9765, 22591,  2015,  1037,  4895,  9765,  9691,  6784,  2080,\n",
      "          2139, 10861,  3050, 23689,  6590,  6072,  7367,  4372, 10010,  9077,\n",
      "          2078,  2139,  2474,  3968, 18100, 10446,  4372,  3290,  1012,   102],\n",
      "        [  101,  1045, 19696,  2140, 10861,  3449, 18440, 14289,  8743,  2080,\n",
      "         15775,  7011,  1061,  2474, 25416, 26455,  2401, 10861,  2053,  2909,\n",
      "          3726, 11498, 23233,  2050,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,   100,  9033,  6633, 28139,  9706, 18232, 15482,  4168,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9686,  4842,  2080, 10861,  2702, 12617, 14163,  2100, 14753,\n",
      "          9956, 22939,  1010, 28681,  2080, 12436,  1037,  9765,  2906, 29316,\n",
      "           100,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10861,  8915,  2712, 23310,  2063,  1061,  8915,  2033,  5558,\n",
      "          6072,  4013, 13663, 10861, 14615,  2080,   100,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.1565,  1.0695],\n",
      "        [ 2.0595, -1.8850],\n",
      "        [ 1.7714, -1.6318],\n",
      "        [ 0.4192, -0.4180],\n",
      "        [ 1.1322, -0.9670]]), hidden_states=None, attentions=None)\n",
      "tensor([[0.0974, 0.9026],\n",
      "        [0.9810, 0.0190],\n",
      "        [0.9678, 0.0322],\n",
      "        [0.6979, 0.3021],\n",
      "        [0.8908, 0.1092]])\n",
      "tensor([1, 0, 0, 0, 0])\n",
      "['POSITIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "tokenizer_spanish = AutoTokenizer.from_pretrained(model_name_2)\n",
    "model_spanish = AutoModelForSequenceClassification.from_pretrained(model_name_2) \n",
    "\n",
    "text = [\"Estamos a un estornudo de que los militares se encarguen de la EducaciÃ³n en MÃ©xico.\", \n",
    "       \"IGUAL QUE EL AEROPUERTO CHAFA Y LA REFINERIA QUE NO SIRVE PARA NADA\", \n",
    "       \"ðŸ¥°ðŸ¥°ðŸ¥° siempre apoyÃ¡ndome\", \n",
    "       \"Espero que tengas muy bonito dÃ­a, todo va a estar bien ðŸ¤\",\n",
    "        \"QuÃ© te sea leve y te mejores pronto querido âœ¨\"]\n",
    "\n",
    "batch = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "print(batch)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    print(outputs)\n",
    "    \n",
    "    #inside tensor([[are the probabilities]])\n",
    "    predictions = F.softmax(outputs.logits, dim=1)\n",
    "    print(predictions)\n",
    "    \n",
    "    #give us the max and min\n",
    "    labels = torch.argmax((predictions), dim=1)\n",
    "    print(labels)\n",
    "    \n",
    "    #id2label give us the class name POSITIVE NEGATIVE\n",
    "    labels = [model.config.id2label[label_id] for label_id in labels.tolist()]\n",
    "    print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb221f",
   "metadata": {},
   "source": [
    "# TEST PIO TRANSLATE SPANISH TO ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7c2d067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'NEGATIVE', 'score': 0.729952871799469}\n",
      "{'label': 'NEGATIVE', 'score': 0.9986312985420227}\n",
      "{'label': 'POSITIVE', 'score': 0.9996458292007446}\n",
      "{'label': 'POSITIVE', 'score': 0.9998538494110107}\n",
      "{'label': 'POSITIVE', 'score': 0.9941353797912598}\n"
     ]
    }
   ],
   "source": [
    "#Tried to used a spanish model but it didn't work, so I translate it to english and it worked better\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "example_results_5= classifier([\"We are one sneeze away from the military taking over education in Mexico.\",\n",
    "       \"SAME AS THE CHAFA AIRPORT AND THE REFINERY THAT IS USELESS FOR NOTHING\",\n",
    "       \" ðŸ¥°ðŸ¥°ðŸ¥° always supporting me\", \n",
    "        \"I hope you have a very nice day, everything will be fine ðŸ¤\",\n",
    "    \"May it be light to you and get better soon dear âœ¨\"])\n",
    "\n",
    "for results in example_results_5:\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b785d",
   "metadata": {},
   "source": [
    "# MAKE YOUR OWN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00b54dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to for more documentation huggingface.co/transformers/v3.2.0/custom_datasets.html\n",
    "#there are five steps you need to follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Prepare dataset (loaded from a csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f728303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. load pretrained tokenizer then call it with dataset -> encoding (token ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daef710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. build a PyTorch dataset with encodings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183adb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. load pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed180e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. a)load trainer and train it b)or use native Pytorchtraining pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93695435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47ed52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17716282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63609b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5ae42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2577f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0f2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d6584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
